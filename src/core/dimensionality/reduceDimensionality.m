function [reducedFeatures, info] = reduceDimensionality(features, method, params, labels)
% REDUCEDIMENSIONALITY Redukuje wymiarowo≈õƒá cech u≈ºywajƒÖc wybranej metody
%
% Funkcja implementuje algorytmy redukcji wymiarowo≈õci dla cech odcisk√≥w palc√≥w,
% zmniejszajƒÖc liczbƒô wymiar√≥w przy zachowaniu najwa≈ºniejszych informacji.
% Obs≈Çuguje metody nadzorowane (MDA) i nienadzorowane (PCA) z automatycznym
% doborem parametr√≥w i raportowaniem jako≈õci redukcji.
%
% Parametry wej≈õciowe:
%   features - macierz cech [samples √ó features] do redukcji
%   method - nazwa metody ('PCA', 'MDA')
%   params - struktura parametr√≥w specyficznych dla metody
%   labels - etykiety klas [samples √ó 1] (wymagane dla MDA, opcjonalne dla PCA)
%
% Parametry wyj≈õciowe:
%   reducedFeatures - macierz zredukowanych cech [samples √ó reduced_dims]
%   info - struktura z informacjami o redukcji (method, explained variance, etc.)
%
% Dostƒôpne metody:
%   PCA: Principal Component Analysis - analiza sk≈Çadowych g≈Ç√≥wnych
%   MDA: Multiple Discriminant Analysis - analiza dyskryminacyjna
%
% Przyk≈Çad u≈ºycia:
%   [redFeats, info] = reduceDimensionality(features, 'PCA', params);

if nargin < 4
    labels = [];
end

fprintf('üîç Applying %s...\n', upper(method));

switch lower(method)
    case 'pca'
        [reducedFeatures, info] = applyPCA(features, params);
        
    case 'mda'
        if isempty(labels)
            error('MDA requires labels for supervised learning');
        end
        [reducedFeatures, info] = applyMDA(features, labels, params);
        
    otherwise
        error('Unknown dimensionality reduction method: %s. Available: PCA, MDA', method);
end

% Raportowanie wynik√≥w (wsp√≥lne dla wszystkich metod)
fprintf('‚úÖ %s completed: %d ‚Üí %d features\n', upper(method), ...
    size(features, 2), size(reducedFeatures, 2));

% Wy≈õwietlenie informacji o zachowanej wariancji je≈õli dostƒôpne
if isfield(info, 'varianceExplained') && ~isempty(info.varianceExplained)
    fprintf('   (%.1f%% variance preserved)\n', info.varianceExplained * 100);
elseif isfield(info, 'totalVarianceExplained') && ~isempty(info.totalVarianceExplained)
    fprintf('   (%.1f%% variance preserved)\n', info.totalVarianceExplained);
end

% Szczeg√≥≈Çowe podsumowanie procesu redukcji
fprintf('\nüìä Dimensionality Reduction Summary:\n');
fprintf('Method: %s\n', upper(method));
fprintf('Original dimensions: %d\n', size(features, 2));
fprintf('Reduced dimensions: %d\n', size(reducedFeatures, 2));
fprintf('Reduction ratio: %.1f%%\n', (1 - size(reducedFeatures, 2)/size(features, 2)) * 100);

% Analiza specyficzna dla metody
switch lower(method)
    case 'mda'
        if isfield(info, 'separabilityScore')
            fprintf('Class separability: %.3f\n', info.separabilityScore);
        end
        if isfield(info, 'eigenValues') && ~isempty(info.eigenValues)
            fprintf('Top eigenvalues: %s\n', mat2str(info.eigenValues(1:min(3, end))', 3));
        end
        
    case 'pca'
        if isfield(info, 'explained') && ~isempty(info.explained)
            topComponents = min(3, length(info.explained));
            fprintf('Top %d components explain: %.1f%% variance\n', ...
                topComponents, sum(info.explained(1:topComponents)));
            fprintf('Individual variance: %s%%\n', ...
                mat2str(info.explained(1:topComponents)', 1));
        end
end
end

%% FUNKCJE IMPLEMENTUJƒÑCE POSZCZEG√ìLNE METODY

function [reducedFeatures, info] = applyPCA(features, params)
% APPLYPCA Implementuje Principal Component Analysis
%
% Metoda nienadzorowana znajdujƒÖca kierunki maksymalnej wariancji w danych.
% Redukuje wymiarowo≈õƒá poprzez projekcjƒô na sk≈Çadowe g≈Ç√≥wne zachowujƒÖce
% zadany procent ca≈Çkowitej wariancji.

% Ustawienia domy≈õlne dla PCA
if ~isfield(params, 'varianceThreshold')
    params.varianceThreshold = 0.95; % Zachowaj 95% wariancji
end

if ~isfield(params, 'maxComponents')
    params.maxComponents = min(size(features, 1) - 1, 15); % Maksymalnie 15 komponent√≥w
end

fprintf('   Target variance preserved: %.1f%%\n', params.varianceThreshold * 100);

% Wykonanie PCA u≈ºywajƒÖc wbudowanej funkcji MATLAB
[coeff, score, latent, ~, explained] = pca(features);

% Obliczenie kumulatywnej wariancji wyja≈õnionej
cumulativeVariance = cumsum(explained) / 100;

% Znajd≈∫ liczbƒô komponent√≥w dla ≈ºƒÖdanej wariancji
numComponents = find(cumulativeVariance >= params.varianceThreshold, 1, 'first');

% Ograniczenie do maksymalnej liczby komponent√≥w
numComponents = min(numComponents, params.maxComponents);

% Fallback je≈õli nie znaleziono odpowiedniej liczby komponent√≥w
if isempty(numComponents)
    numComponents = params.maxComponents;
end

% Projekcja na wybrane sk≈Çadowe g≈Ç√≥wne
reducedFeatures = score(:, 1:numComponents);

% Tworzenie struktury informacyjnej
info = struct();
info.method = 'PCA';
info.numComponents = numComponents;
info.coefficients = coeff(:, 1:numComponents);    % Wektory w≈Çasne
info.eigenvalues = latent(1:numComponents);       % Warto≈õci w≈Çasne
info.explained = explained(1:numComponents);      % Wyja≈õniona wariancja per komponent
info.varianceExplained = cumulativeVariance(numComponents);
info.totalVarianceExplained = sum(explained(1:numComponents));
info.originalDims = size(features, 2);
info.reducedDims = numComponents;
end

function [reducedFeatures, info] = applyMDA(features, labels, params)
% APPLYMDA Implementuje Multiple Discriminant Analysis (Enhanced LDA)
%
% Metoda nadzorowana maksymalizujƒÖca separowalno≈õƒá miƒôdzy klasami przy
% minimalizacji wariancji wewnƒÖtrz klas. Znajduje kierunki optymalnej
% dyskryminacji miƒôdzy klasami odcisk√≥w palc√≥w.

% Ustawienia domy≈õlne dla MDA
if ~isfield(params, 'maxComponents')
    params.maxComponents = 4; % Maksymalnie 4 komponenty dyskryminujƒÖce
end

fprintf('   Target components: %d\n', params.maxComponents);

% Obliczenie rzeczywistej liczby mo≈ºliwych komponent√≥w
numClasses = length(unique(labels));
actualComponents = min(numClasses - 1, params.maxComponents);

% Przygotowanie danych per klasa
classLabels = unique(labels);
classFeatures = cell(length(classLabels), 1);
classMeans = zeros(length(classLabels), size(features, 2));

for i = 1:length(classLabels)
    classIdx = labels == classLabels(i);
    classFeatures{i} = features(classIdx, :);
    classMeans(i, :) = mean(classFeatures{i}, 1);
end

% Obliczenie macierzy rozrzutu miƒôdzy klasami (between-class scatter)
overallMean = mean(features, 1);
Sb = zeros(size(features, 2));

for i = 1:length(classLabels)
    classSize = sum(labels == classLabels(i));
    meanDiff = classMeans(i, :) - overallMean;
    Sb = Sb + classSize * (meanDiff' * meanDiff);
end

% Obliczenie macierzy rozrzutu wewnƒÖtrz klas (within-class scatter)
Sw = zeros(size(features, 2));

for i = 1:length(classLabels)
    classData = classFeatures{i};
    classMean = classMeans(i, :);
    
    for j = 1:size(classData, 1)
        diff = classData(j, :) - classMean;
        Sw = Sw + (diff' * diff);
    end
end

% Regularyzacja macierzy Sw je≈õli singular
if rank(Sw) < size(Sw, 1)
    fprintf('   Adding regularization...\n');
    Sw = Sw + 1e-6 * eye(size(Sw)); % Regularyzacja Ridge
end

% RozwiƒÖzanie uog√≥lnionego problemu warto≈õci w≈Çasnych
try
    [eigenvectors, eigenvalues] = eig(Sb, Sw);
    [~, sortIdx] = sort(diag(eigenvalues), 'descend');
    
    % Wyb√≥r najlepszych komponent√≥w dyskryminujƒÖcych
    selectedVectors = eigenvectors(:, sortIdx(1:actualComponents));
    eigenVals = diag(eigenvalues);
    eigenVals = eigenVals(sortIdx(1:actualComponents));
    
    % Transformacja cech do przestrzeni dyskryminujƒÖcej
    reducedFeatures = features * selectedVectors;
    
catch ME
    fprintf('   MDA eigenvalue solution failed: %s\n', ME.message);
    fprintf('   Fallback to PCA...\n');
    
    % Fallback: u≈ºyj PCA je≈õli MDA nie dzia≈Ça
    params_fallback = struct('varianceThreshold', 0.90, 'maxComponents', actualComponents);
    [reducedFeatures, info] = applyPCA(features, params_fallback);
    info.method = 'MDA (PCA fallback)';
    return;
end

% Tworzenie struktury informacyjnej
info = struct();
info.method = 'MDA';
info.numComponents = actualComponents;
info.transformMatrix = selectedVectors;           % Macierz transformacji
info.eigenValues = eigenVals;                    % Warto≈õci w≈Çasne
info.originalDims = size(features, 2);
info.reducedDims = actualComponents;

% Obliczenie miary separowalno≈õci klas
info.separabilityScore = calculateClassSeparability(reducedFeatures, labels);
end

function separabilityScore = calculateClassSeparability(projectedData, labels)
% CALCULATECLASSSEPARABILITY Oblicza miarƒô separowalno≈õci klas w przestrzeni zredukowanej
%
% Funkcja oblicza stosunek wariancji miƒôdzy klasami do wariancji wewnƒÖtrz klas
% jako miarƒô jako≈õci separacji. Wy≈ºsze warto≈õci oznaczajƒÖ lepszƒÖ separowalno≈õƒá.

try
    uniqueLabels = unique(labels);
    numClasses = length(uniqueLabels);
    
    if numClasses < 2
        separabilityScore = 0;
        return;
    end
    
    % Obliczenie sk≈Çadnik√≥w separowalno≈õci
    betweenClassVar = 0;
    withinClassVar = 0;
    globalMean = mean(projectedData, 1);
    
    for i = 1:numClasses
        classMask = labels == uniqueLabels(i);
        classData = projectedData(classMask, :);
        
        if isempty(classData)
            continue;
        end
        
        classMean = mean(classData, 1);
        classSize = sum(classMask);
        
        % Wariancja miƒôdzy klasami (between-class variance)
        meanDiff = classMean - globalMean;
        betweenClassVar = betweenClassVar + classSize * sum(meanDiff.^2);
        
        % Wariancja wewnƒÖtrz klasy (within-class variance)
        if classSize > 1
            classVar = sum(var(classData, 0, 1));
            withinClassVar = withinClassVar + classVar;
        end
    end
    
    % Obliczenie separability score jako stosunku wariancji
    if withinClassVar > 1e-10
        separabilityScore = betweenClassVar / withinClassVar;
    else
        separabilityScore = betweenClassVar; % Idealna separacja
    end
    
    % Sanityzacja wyniku
    if ~isfinite(separabilityScore) || separabilityScore < 0
        separabilityScore = 0;
    end
    
catch ME
    separabilityScore = 0; % Fallback dla b≈Çƒôd√≥w
end
end