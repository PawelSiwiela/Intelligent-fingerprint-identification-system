function [bestHyperparams, bestScore, allResults] = optimizeHyperparameters(trainData, valData, modelType, numTrials, imagesData, logFile)
% OPTIMIZEHYPERPARAMETERS Optymalizacja hiperparametr√≥w metodƒÖ Random Search
%
% Funkcja implementuje Random Search dla znajdowania optymalnych hiperparametr√≥w
% modeli klasyfikacji odcisk√≥w palc√≥w. Wykorzystuje strategiƒô pr√≥b losowych
% z deterministycznym seedem, early stopping oraz zaawansowane logowanie.
% Zoptymalizowana specjalnie dla PatternNet z konserwatywnym podej≈õciem.
%
% Parametry wej≈õciowe:
%   trainData - dane treningowe do optymalizacji:
%              .features - macierz cech [samples √ó features]
%              .labels - wektor etykiet [samples √ó 1]
%   valData - dane walidacyjne do ewaluacji:
%            .features/.labels - analogiczne do trainData
%   modelType - typ modelu: 'patternnet' lub 'cnn'
%   numTrials - liczba pr√≥b Random Search (domy≈õlnie 30)
%   imagesData - dane obrazowe dla CNN (opcjonalne dla PatternNet)
%   logFile - uchwyt pliku log√≥w (opcjonalny)
%
% Parametry wyj≈õciowe:
%   bestHyperparams - struktura z najlepszymi hiperparametrami
%   bestScore - najlepsza accuracy walidacyjna [0-1]
%   allResults - array struktur z wszystkimi wynikami (posortowane malejƒÖco)
%
% Strategia Random Search:
%   1. Konserwatywne zakresy hiperparametr√≥w (sprawdzone empirycznie)
%   2. Deterministyczny seed per trial dla reprodukowalno≈õci
%   3. Early stopping przy 90% accuracy (oszczƒôdno≈õƒá czasu)
%   4. Ranking wszystkich pr√≥b wed≈Çug accuracy walidacyjnej
%   5. Szczeg√≥≈Çowe logowanie ka≈ºdej pr√≥by
%
% Zoptymalizowana konfiguracja PatternNet:
%   - Architektury: [5], [10], [15], [20] neuron√≥w (tylko sprawdzone)
%   - Algorytm: trainscg (Scaled Conjugate Gradient)
%   - Funkcja kosztu: MSE (Mean Squared Error)
%   - Epoki: 15-25 (kr√≥tkie dla szybko≈õci)
%   - Learning rate: 5e-4, 1e-3 (konserwatywne)
%   - Early stopping: 1-2 failures (agresywne zatrzymanie)
%
% Przyk≈Çad u≈ºycia:
%   [bestParams, bestAcc, results] = optimizeHyperparameters(train, val, 'patternnet', 30);

% OBS≈ÅUGA PARAMETR√ìW OPCJONALNYCH
if nargin < 4, numTrials = 30; end
if nargin < 5, imagesData = []; end
if nargin < 6, logFile = []; end

fprintf('\nüîç RANDOM SEARCH OPTIMIZATION for %s (%d trials)\n', upper(modelType), numTrials);
fprintf('========================================================\n');

% INICJALIZACJA LOGOWANIA
if ~isempty(logFile)
    logInfo(sprintf('Starting Random Search optimization for %s (%d trials)', upper(modelType), numTrials), logFile);
end

% INICJALIZACJA ZMIENNYCH WYNIKOWYCH
bestScore = 0;              % Najlepsza accuracy walidacyjna
bestHyperparams = [];       % Najlepsze hiperparametry
allResults = [];            % Historia wszystkich pr√≥b

% G≈Å√ìWNA PƒòTLA RANDOM SEARCH
for trial = 1:numTrials
    fprintf('  Trial %2d/%d: ', trial, numTrials);
    
    switch lower(modelType)
        case 'patternnet'
            % GENERATOR HIPERPARAMETR√ìW PATTERNNET (zoptymalizowany)
            hyperparams = generatePatternNetHyperparams(trial);
            [score, trainTime] = evaluatePatternNet(hyperparams, trainData, valData);
            
        case 'cnn'
            % GENERATOR HIPERPARAMETR√ìW CNN (oryginalny, bez zmian)
            hyperparams = generateCNNParams();
            [score, trainTime] = evaluateCNN(hyperparams, imagesData);
            
        otherwise
            error('Unsupported model type: %s. Supported: patternnet, cnn', modelType);
    end
    
    % ZAPISZ WYNIK AKTUALNEJ PR√ìBY
    result = struct();
    result.hyperparams = hyperparams;
    result.score = score;
    result.trainTime = trainTime;
    result.trial = trial;
    allResults = [allResults; result];
    
    % SPRAWD≈π CZY TO NOWY NAJLEPSZY WYNIK
    if score > bestScore
        bestScore = score;
        bestHyperparams = hyperparams;
        fprintf('üéØ NEW BEST! Score: %.3f (%.1fs)\n', score, trainTime);
        
        % LOGOWANIE NOWEGO REKORDU
        if ~isempty(logFile)
            logInfo(sprintf('NEW BEST %s score: %.3f (trial %d/%d)', upper(modelType), score, trial, numTrials), logFile);
        end
        
        % EARLY STOPPING - przerwij optymalizacjƒô przy 90% accuracy
        if score >= 0.90
            fprintf('üõë EARLY STOPPING! Achieved %.1f%% accuracy (target: 90%%)\n', score * 100);
            
            if ~isempty(logFile)
                logInfo(sprintf('EARLY STOPPING %s optimization at %.1f%% accuracy (trial %d/%d)', upper(modelType), score * 100, trial, numTrials), logFile);
            end
            
            break; % Wyjd≈∫ z pƒôtli optymalizacji
        end
    else
        fprintf('Score: %.3f (%.1fs)\n', score, trainTime);
    end
end

% POST-PROCESSING WYNIK√ìW
% Sortuj wszystkie wyniki wed≈Çug accuracy (malejƒÖco)
[~, sortIdx] = sort([allResults.score], 'descend');
allResults = allResults(sortIdx);

% PODSUMOWANIE KO≈ÉCOWE
fprintf('\nüìä OPTIMIZATION SUMMARY:\n');
fprintf('========================\n');
fprintf('Best validation accuracy: %.3f%% (%.1f%%)\n', bestScore, bestScore * 100);
fprintf('Total trials completed: %d/%d\n', length(allResults), numTrials);
fprintf('Improvement achieved: %.1f%% ‚Üí %.1f%% (Œî=%.1f%%)\n', ...
    allResults(end).score * 100, bestScore * 100, (bestScore - allResults(end).score) * 100);

% KO≈ÉCOWE LOGOWANIE
if ~isempty(logFile)
    logInfo(sprintf('%s optimization completed: Best score %.3f%% after %d trials', ...
        upper(modelType), bestScore * 100, length(allResults)), logFile);
end
end

%% GENERATOR HIPERPARAMETR√ìW DLA PATTERNNET (ZOPTYMALIZOWANY)

function hyperparams = generatePatternNetHyperparams(trial)
% GENERATEPATTERNETHYPERPARAMS Ultra-konserwatywny generator dla PatternNet
%
% Generator zoptymalizowany na podstawie empirycznych wynik√≥w, zawƒô≈ºajƒÖcy
% przestrze≈Ñ poszukiwa≈Ñ do najlepiej dzia≈ÇajƒÖcych konfiguracji.
% Priorytet: szybko≈õƒá + stabilno≈õƒá + wysoka accuracy (95%+).

% ARCHITEKTURA: Tylko sprawdzone, ma≈Çe sieci (unikanie overfitting)
validArchitectures = {[5], [10], [15], [20]};

% ALGORYTM TRENOWANIA: Tylko trainscg (najstabilniejszy dla ma≈Çych sieci)
trainFunctions = {'trainscg'};

% FUNKCJA KOSZTU: Tylko MSE (najlepsza dla klasyfikacji wzorc√≥w)
performFunctions = {'mse'};

% LICZBA EPOK: Kr√≥tka (15-25) dla szybko≈õci i unikania overfitting
epochsOptions = [15, 20, 25];

% LEARNING RATE: Konserwatywne warto≈õci (stabilna zbie≈ºno≈õƒá)
lrOptions = [5e-4, 1e-3];

% PR√ìG ZATRZYMANIA: Wy≈ºsze warto≈õci (wcze≈õniejsze zatrzymanie)
goalOptions = [2e-3, 3e-3];

% MAX FAIL: Bardzo agresywne early stopping (1-2 niepowodzenia)
maxFailOptions = [1, 2];

% DETERMINISTYCZNY WYB√ìR NA PODSTAWIE NUMERU PR√ìBY
hyperparams = struct();

% Cykliczny wyb√≥r architektury
hyperparams.hiddenSizes = validArchitectures{mod(trial-1, length(validArchitectures)) + 1};

% Zawsze te same sprawdzone opcje
hyperparams.trainFcn = trainFunctions{1};    % Zawsze 'trainscg'
hyperparams.performFcn = performFunctions{1}; % Zawsze 'mse'

% LOSOWY WYB√ìR POZOSTA≈ÅYCH PARAMETR√ìW (z deterministycznym seedem)
rng(trial * 123); % Unikalny seed per trial

hyperparams.epochs = epochsOptions(randi(length(epochsOptions)));
hyperparams.lr = lrOptions(randi(length(lrOptions)));
hyperparams.goal = goalOptions(randi(length(goalOptions)));
hyperparams.max_fail = maxFailOptions(randi(length(maxFailOptions)));

% PARAMETRY LEVENBERG-MARQUARDT (dla kompatybilno≈õci)
hyperparams.mu = 0.01;      % Wy≈ºsza warto≈õƒá poczƒÖtkowa
hyperparams.mu_dec = 0.2;   % Bardziej agresywne zmniejszanie
hyperparams.mu_inc = 15;    % Szybsze zwiƒôkszanie przy niepowodzeniu

% DEBUG: Wy≈õwietl konfiguracjƒô aktualnej pr√≥by
fprintf('[Arch=%s, Train=%s, E=%d, LR=%.1e, Goal=%.1e, MaxFail=%d] ', ...
    mat2str(hyperparams.hiddenSizes), hyperparams.trainFcn, ...
    hyperparams.epochs, hyperparams.lr, hyperparams.goal, hyperparams.max_fail);
end

%% EWALUATOR PATTERNNET (ULEPSZONA WERSJA)

function [score, trainTime] = evaluatePatternNet(hyperparams, trainData, valData)
% EVALUATEPATTERNNET Deterministyczna ewaluacja PatternNet z diagnostykƒÖ
%
% Funkcja trenuje i testuje PatternNet z podanymi hiperparametrami,
% implementujƒÖc szczeg√≥≈ÇowƒÖ diagnostykƒô dla wykrywania problem√≥w
% z klasyfikacjƒÖ (np. single-class prediction).

tic;

try
    % DETERMINISTYCZNY SEED dla reprodukowalno≈õci wynik√≥w
    rng(42, 'twister');
    
    % ETAP 1: Tworzenie sieci PatternNet
    net = createPatternNet(hyperparams);
    
    % ETAP 2: Przygotowanie danych treningowych
    X_train = trainData.features';           % Transpozycja dla PatternNet [features √ó samples]
    T_train = full(ind2vec(trainData.labels', 5)); % One-hot encoding [classes √ó samples]
    
    % DIAGNOSTYKA: Sprawd≈∫ r√≥≈ºnorodno≈õƒá klas treningowych
    uniqueTrainLabels = unique(trainData.labels);
    fprintf('Train classes: %s ', mat2str(uniqueTrainLabels));
    
    % ETAP 3: Trening sieci (z wy≈ÇƒÖczonymi ostrze≈ºeniami)
    warning('off', 'all');
    trainedNet = train(net, X_train, T_train);
    warning('on', 'all');
    
    % ETAP 4: Predykcja na danych walidacyjnych
    X_val = valData.features';
    Y_val = trainedNet(X_val);                % Wyj≈õcie sieci [classes √ó samples]
    [~, predicted] = max(Y_val, [], 1);       % Wyb√≥r klasy z max prawdopodobie≈Ñstwem
    
    % DIAGNOSTYKA: Sprawd≈∫ r√≥≈ºnorodno≈õƒá predykcji
    uniquePredicted = unique(predicted);
    fprintf('Predicted: %s ', mat2str(uniquePredicted));
    
    % ETAP 5: Obliczenie accuracy
    score = sum(predicted == valData.labels') / length(valData.labels);
    
    % DIAGNOSTYKA: Ostrze≈ºenie o single-class prediction
    if length(uniquePredicted) == 1
        fprintf('‚ö†Ô∏è SINGLE CLASS! ');
        % Single-class prediction czƒôsto wskazuje na problemy z overfitting lub
        % zbyt wysokie learning rate / zbyt ma≈ÇƒÖ regularyzacjƒô
    end
    
    trainTime = toc;
    
catch ME
    % OBS≈ÅUGA B≈ÅƒòD√ìW TRENOWANIA
    fprintf('FAILED: %s ', ME.message);
    score = 0;      % Najgorszy mo≈ºliwy wynik
    trainTime = toc;
end
end

%% GENERATOR I EWALUATOR CNN (BEZ ZMIAN - ORYGINALNY KOD)

function hyperparams = generateCNNParams()
% GENERATECNNPARAMS Generator hiperparametr√≥w CNN (oryginalny kod)
%
% Pozostaje bez zmian - Random Search dla CNN z szerokim zakresem parametr√≥w.

filterSizes = [3, 5, 7];

hyperparams = struct();
hyperparams.filterSize = filterSizes(randi(length(filterSizes)));
hyperparams.numFilters1 = randi([8, 32]);
hyperparams.numFilters2 = randi([16, 64]);
hyperparams.numFilters3 = randi([32, 128]);
hyperparams.dropoutRate = 0.2 + rand() * 0.3;  % 0.2-0.5
hyperparams.lr = 10^(-3.5 + rand() * 1);       % 10^-3.5 do 10^-2.5
hyperparams.l2reg = 10^(-6 + rand() * 3);      % 10^-6 do 10^-3
hyperparams.epochs = randi([5, 20]);

batchSizes = [4, 8, 16];
hyperparams.miniBatchSize = batchSizes(randi(length(batchSizes)));
end

function [score, trainTime] = evaluateCNN(hyperparams, imagesData)
% EVALUATECNN Ewaluator CNN (oryginalny kod)
%
% Pozostaje bez zmian - trening i ewaluacja CNN na danych obrazowych.

tic;

try
    if isempty(imagesData) || ~isfield(imagesData, 'X_train')
        error('Images data required for CNN evaluation');
    end
    
    inputSize = size(imagesData.X_train);
    if length(inputSize) >= 4
        inputSize = inputSize(1:3);  % [height, width, channels]
    else
        error('Invalid image data format for CNN');
    end
    
    % Utw√≥rz i trenuj CNN
    cnnStruct = createCNN(hyperparams, 5, inputSize);
    trainedNet = trainNetwork(imagesData.X_train, imagesData.Y_train, ...
        cnnStruct.layers, cnnStruct.options);
    
    % Ewaluacja na zbiorze walidacyjnym
    predicted = classify(trainedNet, imagesData.X_val);
    score = sum(predicted == imagesData.Y_val) / length(imagesData.Y_val);
    
    trainTime = toc;
    
catch ME
    fprintf('FAILED: %s ', ME.message);
    score = 0;
    trainTime = toc;
end
end